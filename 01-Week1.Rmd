# Week 1
```{r include=FALSE}
# automatically create a bib database for R packages
```

## Mini-Example
### Task Description
The goal of the mini-example is to examine the association between firm’s discretionary spending (advertising, R&D) and top-line financial impact (sales)

- How many variables are in the dataset? Which ones are identifier, categorical vs. continuous?
- What is(are) the focal outcome variable(s)?
- What is(are) the focal predictor variable(s)?
- What is(are) the focal “control” variable(s)?
- What is the mean of sales, advertising and R&D?
- How are sales, advertising and R&D different in b2b vs. b2c firms?
- How do advertising and R&D affect sales?

### Variables in the Data
| Variable Name |What does it mean? | 
|---------------|:-------------:|
| gvkey          |6-digit Firm id| 
| datadate       |fiscal year    |
| pure_b2b       |Indicator: Only in B2B sector (1) – otherwise (0)|
| Sales |  Sales in Millions of Dollars|
| xad |Advertising expenditure in millions of dollars|
| xrd |R&D expenditure in millions of dollars|
| fmsize_at |Natural log of the book value of total assets|
| mksh2 |Ratio of firm’s overall sales revenue to the sales revenue of all firms in the same 2-digit SIC code industry|






### Analysis using R

Before beginning the tutorial, we need to make sure all necessary packages are installed.  If any of these packages are not installed, write `install.packages("<name of package>")`. For example, to install the package `dplyr`, use `install.packages("dplyr")`.

The next step is to include all the libraries we use in this exercise. An alternative approach is to load libraries specific to a function before using the function.
```{r include=TRUE , warning= FALSE,message=FALSE}
library(readxl)
library(dplyr)
library(ggplot2)
library(fBasics)
```

The next step is to import data. We will use the `read_excel` function to import excel file into R.

You can use the [*setwd*](http://rfunction.com/archives/1001) function to set the working directory to the folder which has your data or give the full path of your excel file wile reading the excel file.

```{r include=TRUE }
# Importing Data
mini_case_data <- read_excel("Mini-case data.xlsx")
```

#### Summary Statistics

In R, there are multiple ways to check the summary statistics of your variables. ([Link 1](http://www.sthda.com/english/wiki/descriptive-statistics-and-graphics),[Link 2](https://www.statmethods.net/stats/descriptives.html))

```{r include=TRUE }
# Make a list of variables you want summary statistics for
var_list <- c("sales","xad","xrd")
# Make a data.frame containing summary statistics of interest
summ_stats <- fBasics::basicStats(mini_case_data[var_list])
summ_stats <- as.data.frame(t(summ_stats))
# Rename some of the columns for convenience
summ_stats <- summ_stats %>% select("nobs","Mean", "Stdev", "Minimum", "Maximum")
summ_stats <- summ_stats %>% rename('N'= 'nobs')
```
```{r echo=FALSE }
knitr::kable(summ_stats, format = "html")
```
We can also compare summary statistics by grouping the data based on some categorical variables.

In our case, we will group the data by *pure_b2b* and compare the summary statistics
```{r include=TRUE,message=FALSE }
# Summary stats - sales
summary_sales_by_group <- mini_case_data %>% group_by(pure_b2b)%>% summarise(n = n(), mean_sales = mean(sales),std_dev_sales = sd(sales), min_sale = min(sales), max_sales = max(sales) )


```
```{r echo=FALSE }
knitr::kable(summary_sales_by_group, format = "html")
```
Similarly we can compare for other variables.

#### Graph of Mean Sales (B2B vs. non-B2B Firms)

We can plot the mean sales for B2B vs. non-B2B Firms. You can use the code below as reference to plot other variables such as xad and xrd.

```{r include=TRUE }
# Convert pure_b2b as a factor variable

summary_sales_by_group$pure_b2b <- as.factor(summary_sales_by_group$pure_b2b)

# Plot
ggplot(summary_sales_by_group, aes(x = pure_b2b, y =mean_sales )) +
    geom_bar(stat = "identity") + 
    ylab("Mean Sales") +
    ggtitle("Mean of Sales by pure_b2b")

```

#### Sales Regression

For our sales regression

  - Dependent Variable : sales
  - Independet Variables: xad,xrd

```{r include=TRUE }
sales_regression  <-  lm(sales ~ xad+xrd , data =mini_case_data )
# Summary of the regression
sales_regression_coef <- summary(sales_regression)$coefficients

sales_regression_r2 <- summary(sales_regression)$r.squared
```
- Regression Coefficients

  
```{r echo=FALSE }
knitr::kable(sales_regression_coef, format = "html")
```
    -  Advertising (25.0773) and R&D (3.3464) have a positive effect on revenue
    
- R-squared (model fit index) is 
```{r echo=FALSE }
sales_regression_r2
```

We can add more control variables to the regression model

 - Control Variables: pure_b2b, fmsize_at, mksh2
```{r include=TRUE }
sales_regression_with_controls  <-  lm(sales ~ xad+xrd+pure_b2b+fmsize_at+mksh2 ,data =mini_case_data )

# Summary of the regression
sales_regression_with_controls_coef <- summary(sales_regression_with_controls)$coefficients

sales_regression_with_controls_r2 <- summary(sales_regression_with_controls)$r.squared

```
For the new model

- Coefficients
```{r echo=FALSE }
knitr::kable(sales_regression_with_controls_coef, format = "html")
```
  - The relationship between control variables and sales makes sense

- R-squared (model fit index) is 
```{r echo=FALSE }
sales_regression_with_controls_r2
```
   
   - Model fit improves to 0.6434 from 0.5117


## Customer Model Analytics I: Regression Demo
### Task Description

The goal is to predict customer satisfaction for B2B company based on the following variables (See “Regression Demo Satisfaction.xls”)
```{r echo=FALSE }
data_labels <- read_excel("Regression Demo Satisfaction.xlsx", sheet = "Labels")
data_labels <- data_labels[,-3]

knitr::kable(data_labels, format = "html")
```
### Analysis using R
We need to make sure all necessary packages are installed.  If any of these packages are not installed, write `install.packages("<name of package>")`. The next step is to include all the libraries we use in this exercise. 
```{r include=TRUE , warning= FALSE ,message=FALSE}
library(readxl)
library(dplyr)
library(fBasics)
library(car)
```
The next step is to import data. We will use the `read_excel` function to import excel file into R.

```{r include=TRUE }
# Importing Data
satisfaction_data <- read_excel("Regression Demo Satisfaction.xlsx")
```
Some variables can be represented on an interval scale

  - Examples: satisfaction, Income, height, price, and temperature
  
Categorical variables can only be represented on a nominal scale
  
   - Examples: gender, ethnicity, brand, or location

In R, we can convert all the categorical variables into factors.
```{r include=TRUE }
# Importing Data
satisfaction_data$GENDER <- as.factor(satisfaction_data$GENDER)
```

#### Summary Statistics
Review the means of dependent and independent variables.

```{r include=TRUE }
# Make a list of variables you want summary statistics for
var_list <- c("OVERALLSATISFACTION","BID","PSQUAL", "PRICE", "INVOLVEMENT"  )
# Make a data.frame containing summary statistics of interest
summ_stats <- fBasics::basicStats(satisfaction_data[var_list])
summ_stats <- as.data.frame(t(summ_stats))
# Rename some of the columns for convenience
summ_stats <- summ_stats %>% select("nobs","Mean", "Stdev", "Minimum", "Maximum")
summ_stats <- summ_stats %>% rename('N'= 'nobs')
```
```{r echo=FALSE }
knitr::kable(summ_stats, format = "html")
```
- Check if the means and standard deviations “make sense”

- Check the minimum and maximum values and see if they are “correct”

#### Correlation among the variables
Review the correlation among the variables
```{r include=TRUE }
# Check the correlations among variables in var_list 
correlation_matrix <- cor(satisfaction_data[var_list])
# Rounding off to two digits
correlation_matrix <-round(correlation_matrix, 3)
```
```{r echo=FALSE ,warnings = FALSE , message= FALSE}

correlation_matrix %>%
  kableExtra::kbl() %>%
  kableExtra::kable_paper("basic", full_width = F)
```


- You want to see high correlation between the dependent variable and independent variables.

- You do want to see tremendously high correlation among the independent variables (since they should ideally capture different factors driving the dependent variable).


#### Regression with one covariate

Let’s examine the statistical relationship between overall satisfaction and satisfaction with bidding

-  Dependent variable: OVERALLSATISFACTION 

-  Independent variable(s): BID

```{r include=TRUE }
satisfaction_regression  <-  lm(OVERALLSATISFACTION ~ BID , data =satisfaction_data )
# Summary of the regression
satisfaction_regression_coef <- summary(satisfaction_regression)$coefficients

satisfaction_regression_r2 <- summary(satisfaction_regression)$r.squared
```
- Regression Coefficients

  
```{r echo=FALSE }
satisfaction_regression_coef <-round(satisfaction_regression_coef, 3)
knitr::kable(satisfaction_regression_coef, format = "html")
```
    
   -  Implies the following regression model: `Overall satisfaction = 1.898 +  0.642*Bidding Satisfaction`
- R-squared (model fit index) is 
```{r echo=FALSE }
satisfaction_regression_r2
```
#### Regression with all the variables 
Let’s examine the statistical relationship between overall satisfaction and all the variables. 

- Dependent variable: OVERALLSATISFACTION 

- Independent variable(s): BID ,PSQUAL, PRICE, INVOLVEMENT and GENDER  

```{r include=TRUE }
satisfaction_regression_all  <-  lm(OVERALLSATISFACTION ~ BID+PSQUAL+PRICE+INVOLVEMENT+GENDER , data =satisfaction_data )
# Summary of the regression
satisfaction_regression_all_coef <- summary(satisfaction_regression_all)$coefficients

satisfaction_regression_all_r2 <- summary(satisfaction_regression_all)$r.squared
```
- Regression Coefficients

  
```{r echo=FALSE }
satisfaction_regression_all_coef <-round(satisfaction_regression_all_coef, 3)
knitr::kable(satisfaction_regression_all_coef, format = "html")
```
    
   -  Implies the following regression model: `Overall satisfaction = 0.337 +  0.067*Bidding Satisfaction +0.331* Product Quality Satisfaction + 0.147*Price Satisfaction+ 0.392*Involvement -0.061*Gender`
- R-squared (model fit index) is 
```{r echo=FALSE }
satisfaction_regression_all_r2
```
Adding variables to the model changes results

-  Let’s add all the strategic areas
    - Notice the improvement in R-squared
    - Notice the significance of all areas
    
#### Interpreting the output- multicollinearity

Detecting multicollinearity

 - Use VIF (variance inflation factor) defined as [1/(1-R2)]
      - an index that measures how much the variance of a coefficient is increased because of collinearity.
 - Check if VIFs are less than 5 as a rule of thumb.
 
The R function `vif()` [car package] can be used to detect multicollinearity in a regression model:
```{r include=TRUE }
model_vif <- car::vif(satisfaction_regression_all)
```
```{r echo=FALSE }
model_vif <-round(model_vif, 3)
model_vif <- as.data.frame(model_vif)
model_vif <- tibble::rownames_to_column(model_vif, "Variable")
model_vif <-  model_vif %>%   rename( VIF = model_vif)
model_vif %>%
  kableExtra::kbl() %>%
  kableExtra::kable_paper("basic", full_width = F)
```
The VIF score for all the predictor variables is less than 5.

#### Regression is not a mechanical process

- Look at the means of the dependent variables for different levels of each independent variable so you can see if you need to code it as a dummy variable or continuous variable

- Examine the VIFs to ensure your model is reasonably robust and not an artifact of multicollinearity

- Run at least 4-5 different models to get a ‘feel” for the underlying story. Which parameters are stable enough that they don’t change no matter if you drop or add variables?

- Dropping of variables, if necessary, should be done sequentially, one-at-a-time, and with a view to examining:
    - change in R-squared
    - change in /stability of parameters of retained variables
    - managerial implications of dropping the variable on remaining variables

- Do compare the R-squared of different models to see the relative change in model fit. However, sometimes models with lower R-squared are better!

- When is an R-squared “too small”, such that the model is not useful?
    - There is no clear relationship between the value of R-squared and the value of the model. The regression model has value to a firm if it allows the firm to increase its profits, and that is possible even with very small R-squared values.  On the other hand, different model specifications for the same outcome can be compared (ranked) according to the R-squared values.



 
